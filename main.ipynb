{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9UWJEr4lC10v"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from utils.tools import *\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "#from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_xBwuX9C10y"
   },
   "source": [
    "# 01 Problem Description\n",
    "\n",
    "We're trying to predict the ordinal variable damage_grade which represent a level of damage to the building that was hit by the earthquake. There are 3 grades of the damage: 1, 2, 3.\n",
    "\n",
    "#### Description of the dataset\n",
    "\n",
    "The dataset mainly consists of information on the buildings' structure and their legal ownership. Each row in the dataset represents a specific building in the region that was hit by the Gorkha earthquake.\n",
    "\n",
    "* building_id: column unique and random identifier;\n",
    "* geo_level_1_id, geo_level_2_id, geo_level_3_id: geographic region in which building exists, from largest (level 1) to most specific sub-region (level 3). Possible vaules: level 1 $\\in$ [0, 30], level 2 $\\in$ [0, 1427], level 3 $\\in$ [0, 12567];\n",
    "* count_floors_pre_eq: number of floors in the building before earthquake;\n",
    "* age: age of the building in years;\n",
    "* area_percentage: (int) normalized area of the building footprint;\n",
    "* height_percentage: (int) normalized height of the building footprint;\n",
    "* land_surface_condition: (categorical) surface condition of the land where the building was built. Possible values are: 'n', 'o', 't';\n",
    "* fundation_type: (categorical) type of fundation used while building. Possible values are: 'h', 'i', 'r', 'u', 'w';\n",
    "* roof_type: (categorical) type of roof used while building. Possible values are: 'n', 'q', 'x';\n",
    "* ground_floor_type: (categorical) type of the ground floor. Possible values are: 'f', 'm', 'v', 'x', 'z';\n",
    "* other_floor_type: (categorical) type of constructions used in higher than the ground floors (except of roof). Possible values are: 'j', 'q', 's', 'x';\n",
    "* position: (categorical) position of the building. Possible values are: 'j', 'o', 's', 't';\n",
    "* plan_configuration: (categorical) building plan configuration. Possible values are: 'a', 'c', 'd', 'f', 'm', 'n', 'o', 'q', 's', 'u';\n",
    "* has_superstructure_adobe_mud: (binary) flag variable that indicates if the superstructure was made in Adobe/Mud (adobe is a building material made from earth and organic material, it is one of the oldest material used for building structure). Notice that Adobe buildings are particularly susceptible to earthquake damage if they are not reinforced (source: Wikipedia)\n",
    "* has_superstructure_mud_mortar_stone: (binary) flag variable that indicates if the superstructure was mad of Mud Mortar - Stone (it is a mixture of sand, water and clay);\n",
    "* has_secondary_use_\\<school, ... \\>: (binary) flag variable that indicates if the building was used for <...> purposes. \n",
    "* count_families: (int) number of families that live in the building. \n",
    "* legal_ownership_status: (categorical) legal ownership status of the land where building was built. Possible values are: 'a', 'r', 'v', 'w';\n",
    "\n",
    "The data exploration analysis has been performed in the data_exploration notebook.\n",
    "\n",
    "#### Performance Metric\n",
    "\n",
    "To measure the performance of our algorithms, we'll use the F1 score which balances the precision and recall of a classifier. The variant we will use will be the micro averaged F1 score.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anUttr9SC102"
   },
   "source": [
    "# 02 Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "w2FqdSGJC103"
   },
   "outputs": [],
   "source": [
    "df=load_dataset()\n",
    "\n",
    "one_hot_features=[\"legal_ownership_status\",\"land_surface_condition\",\n",
    "                    \"foundation_type\",\"roof_type\",\"ground_floor_type\",\"other_floor_type\",\"position\",\"plan_configuration\"]\n",
    "\n",
    "X=df.drop(columns=[\"building_id\", \"damage_grade\"])\n",
    "y=df[\"damage_grade\"]\n",
    "\n",
    "pp=Preprocessor(compress_cols=False, one_hot_cols=one_hot_features)\n",
    "pp.fit(X,y)\n",
    "X = pp.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9R5Qe27C104"
   },
   "source": [
    "# 03 Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3FusSXbC105"
   },
   "source": [
    "We're gonna create a baseline for standard machine learning model. The data will have a minimal dummy preprocessing that will transform categorical features into numerical ones. No other processing will be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9tltuwX1C105",
    "outputId": "b8b602d7-4a34-4413-9c41-228cfd833cc5"
   },
   "outputs": [],
   "source": [
    "# TRAIN THE MODELS\n",
    "rf_baseline_model = RandomForestClassifier()\n",
    "svc_baseline_model = LinearSVC()\n",
    "lr_baseline_model = LogisticRegression()\n",
    "\n",
    "rf_baseline_model.fit(X, y)\n",
    "svc_baseline_model.fit(X, y)\n",
    "lr_baseline_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_baseline_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m X_test \u001b[39m=\u001b[39m df_test\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mbuilding_id\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m X_test \u001b[39m=\u001b[39m pp\u001b[39m.\u001b[39mtransform(X_test)\n\u001b[1;32m----> 5\u001b[0m y_baseline_rf \u001b[39m=\u001b[39m rf_baseline_model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      6\u001b[0m y_baseline_svc \u001b[39m=\u001b[39m svc_baseline_model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      7\u001b[0m y_baseline_lr \u001b[39m=\u001b[39m lr_baseline_model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf_baseline_model' is not defined"
     ]
    }
   ],
   "source": [
    "# LOAD THE TEST SET \n",
    "df_test = load_dataset(train = False)\n",
    "X_test = df_test.drop(columns=['building_id'])\n",
    "X_test = pp.transform(X_test)\n",
    "\n",
    "# PREDICT\n",
    "y_baseline_rf = rf_baseline_model.predict(X_test)\n",
    "y_baseline_svc = svc_baseline_model.predict(X_test)\n",
    "y_baseline_lr = lr_baseline_model.predict(X_test)\n",
    "\n",
    "# SUBMISSION\n",
    "X_sub_rf = pd.DataFrame(df_test['building_id'])\n",
    "X_sub_svc = pd.DataFrame(df_test['building_id'])\n",
    "X_sub_lr = pd.DataFrame(df_test['building_id'])\n",
    "\n",
    "X_sub_rf['damage_grade'] = y_baseline_rf\n",
    "X_sub_svc['damage_grade'] = y_baseline_svc\n",
    "X_sub_lr['damage_grade'] = y_baseline_lr\n",
    "\n",
    "X_sub_rf.to_csv(\"./prediction/RandomForest_baseline_sub.csv\", index = False)\n",
    "X_sub_svc.to_csv(\"./prediction/SupportVector_baseline_sub.csv\", index = False)\n",
    "X_sub_lr.to_csv(\"./prediction/LogisticRegression_baseline_sub.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lybArfEC107"
   },
   "source": [
    "# 04 Features Creation and Features Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITHhpArhC108"
   },
   "source": [
    "We need to transform non-numerical features into numerical ones. The first step will be to create dummies of the categorical features and drop the building id. The building id should not take part in the classification since it's just an identification number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPLl95voC109"
   },
   "source": [
    "We are gonna incorporate all the similar features 'has_superstructure_\\*' and 'has_secondary_use_*' together through a sum operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "afoY8kAqC109"
   },
   "outputs": [],
   "source": [
    "n_superstructure = np.array(X.loc[:, 'has_superstructure_adobe_mud':'has_superstructure_other']).sum(axis=-1)\n",
    "X['number_of_different_superstructures'] = n_superstructure\n",
    "\n",
    "n_secondary_uses = np.array(X.loc[:, 'has_secondary_use_agriculture':'has_secondary_use_other']).sum(axis=-1)\n",
    "X['number_of_secondary_uses'] = n_secondary_uses\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "t8WcdLrWC10-"
   },
   "source": [
    "# 05 Features Normalization and Target Encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XiYUm-ZTC10_"
   },
   "source": [
    "The scaling of the features, since many of them contains lots of outliers that can interfere with the scaling process, will be done with the RobustScaler.\n",
    "\n",
    "On the geo level id features we perform a target encoding since their cardinality is too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9cpXSBRgC11A",
    "outputId": "85f02a14-e708-451b-9dfb-73ca3345ed8d"
   },
   "outputs": [],
   "source": [
    "# SCALING\n",
    "scaled_cols = ['age', 'area_percentage','count_floors_pre_eq' ,'height_percentage']\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X[scaled_cols])\n",
    "X[scaled_cols] = scaler.transform(X[scaled_cols])\n",
    "\n",
    "# TARGET ENCODING\n",
    "target_cols = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']\n",
    "target_encoder= TargetEncoder(cols=target_cols, min_samples_leaf=20, smoothing=10)\n",
    "target_encoder.fit(X, y)\n",
    "X = target_encoder.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aw1-KM8HC11B"
   },
   "source": [
    "# 06 Grid-search for the classic models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JUQsgwGC11J"
   },
   "source": [
    "#### Logistic Regression Grid-Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5QdLJx_WC11K"
   },
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "    'penalty' : ['l2', 'elasticnet'],\n",
    "    'tol' : [1e-4, 1e-6],\n",
    "    'C' : [0.5, 1.0, 2.0, 5.0],\n",
    "    'random_state' : [42],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'saga'],\n",
    "    'max_iter' : [1000, 5000, 10000],\n",
    "    'multi_class' : ['multinomial']\n",
    "}\n",
    "\n",
    "gs_lr = GridSearchCV(estimator = LogisticRegression(),\n",
    "                    param_grid=lr_params, \n",
    "                    n_jobs=-1, \n",
    "                    verbose=2,\n",
    "                    scoring='f1_micro',\n",
    "                    refit=True)\n",
    "\n",
    "gs_lr.fit(X, y)\n",
    "\n",
    "print(f\"BEST MODEL: {gs_lr.best_estimator_.get_params()}\")\n",
    "print(f\"BEST MEAN SCORE: {gs_lr.best_score_}\")\n",
    "\n",
    "pickle.dump(gs_lr.best_estimator_, open(\"./models/LogisticRegression.pkl\", \"wb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fZUo_bMmC11L"
   },
   "source": [
    "lr = LogisticRegression(C=1.0, \n",
    "                        max_iter=10000, \n",
    "                        multi_class='multinomial', \n",
    "                        penalty='l2',\n",
    "                        random_state=42,\n",
    "                        solver='saga',\n",
    "                        tol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbvrQN8jC11M"
   },
   "source": [
    "#### SVM Grid-Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LerZxz-IC11M"
   },
   "outputs": [],
   "source": [
    "svm_params = {\n",
    "    'C' : [0.1, 1, 5],\n",
    "    'kernel' : ['rbf', 'linear'],\n",
    "    'tol' : [1e-4],\n",
    "    'verbose' : [True],\n",
    "    'random_state' : [42]\n",
    "}\n",
    "\n",
    "gs_svm = GridSearchCV(estimator = SVC(),\n",
    "                      param_grid = svm_params, \n",
    "                      n_jobs=-1, \n",
    "                      verbose = 10, \n",
    "                      scoring='f1_micro',\n",
    "                      refit=True)\n",
    "\n",
    "gs_svm.fit(X, y)\n",
    "\n",
    "print(f\"BEST MODEL: {gs_svm.best_estimator_.get_params()}\")\n",
    "print(f\"BEST MEAN SCORE: {gs_svm.best_score_}\")\n",
    "\n",
    "pickle.dump(gs_svm.best_estimator_, open(\"./models/SVM.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfgyAISGC11N"
   },
   "source": [
    "SVM {C:1, kernel:rbf, tol:1e-4, random_state:42}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpBwcOBTC11B"
   },
   "source": [
    "#### Random Forest Grid-Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=load_dataset()\n",
    "X=df.drop(columns=['damage_grade', 'building_id'])\n",
    "y=df['damage_grade']\n",
    "\n",
    "#Required preprocessing: one hot encoding, target encoding\n",
    "one_hot_cols=[\"legal_ownership_status\",\"land_surface_condition\",\n",
    "                    \"foundation_type\",\"roof_type\",\"ground_floor_type\",\"other_floor_type\",\"position\",\"plan_configuration\"]\n",
    "target_cols=['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']\n",
    "\n",
    "pp=Preprocessor(compress_cols=True, target_cols=target_cols, one_hot_cols=one_hot_cols)\n",
    "pp.fit(X,y)\n",
    "X=pp.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hznXLItuC11C"
   },
   "outputs": [],
   "source": [
    "rf_params = {'n_estimators' : [100, 500, 1000], \n",
    "            'criterion' : ['gini', 'entropy'],\n",
    "            'min_samples_leaf' : [1, 2],\n",
    "            'min_samples_split' : [2, 5],\n",
    "            'random_state' :  [42]\n",
    "            }\n",
    "\n",
    "gs_rf = GridSearchCV(estimator = RandomForestClassifier(), \n",
    "                    param_grid=rf_params, \n",
    "                    n_jobs=-1, \n",
    "                    verbose=2,\n",
    "                    scoring='f1_micro',\n",
    "                    refit=True)\n",
    "\n",
    "gs_rf.fit(X, y)\n",
    "\n",
    "print(f\"BEST MODEL: {gs_rf.best_estimator_.get_params()}\")\n",
    "print(f\"BEST MEAN SCORE: {gs_rf.best_score_}\")\n",
    "\n",
    "pickle.dump(gs_rf.best_estimator_, open(\"./models/RandomForestClassifier.pkl\", \"wb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_best_params={\n",
    "    'criterion': 'entropy',\n",
    "    'min_samples_leaf': 2,\n",
    "    'min_samples_split': 5,\n",
    "    'n_estimators': 1000\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfq5a9MgC11O"
   },
   "source": [
    "# 08 New Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIF1juc-C11T"
   },
   "source": [
    "#### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=load_dataset()\n",
    "X=df.drop(columns=['building_id', 'damage_grade'])\n",
    "y=df['damage_grade']\n",
    "\n",
    "#Required preprocessing: target encoding, identify categorical features\n",
    "target_cols=['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']\n",
    "make_cat_cols = [\"legal_ownership_status\",\"land_surface_condition\",\n",
    "                    \"foundation_type\",\"roof_type\",\"ground_floor_type\",\"other_floor_type\",\"position\",\"plan_configuration\"]\n",
    "\n",
    "pp = Preprocessor(compress_cols=True, target_cols=target_cols, make_cat_cols=make_cat_cols)\n",
    "pp.fit(X,y)\n",
    "X=pp.transform(X)\n",
    "\n",
    "cat_index = [X.columns.get_loc(name) for name in make_cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KHNTBHHgC11T"
   },
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "        \"boosting_type\":[ 'gbdt'],\n",
    "        \"num_leaves\" :[20, 30],\n",
    "        \"max_depth\" :[ -1],\n",
    "        \"learning_rate\" :[0.1, 0.05, 0.01],\n",
    "        \"n_estimators\":[5000],\n",
    "        \"objective\" : [\"multiclass\"],      \n",
    "        \"feature_fraction\" :[0.5, 0.65, 0.8],\n",
    "        \"min_child_weight\" :[0.1, 0.5],\n",
    "        \"max_bin\":[4096, 8192],\n",
    "        \"verbosity\" :[1],\n",
    "        \"num_threads\":[6],\n",
    "        \"seed\":[ 42]\n",
    "        }\n",
    "\n",
    "gs_lgbm = GridSearchCV(estimator = LGBMClassifier(), \n",
    "                    param_grid=lgbm_params, \n",
    "                    verbose=2,\n",
    "                    scoring='f1_micro')\n",
    "\n",
    "gs_lgbm.fit(X, y, categorical_feature=cat_index)\n",
    "\n",
    "print(f\"BEST MODEL: {gs_lgbm.best_estimator_.get_params()}\")\n",
    "print(f\"WITH MEAN SCORE: {gs_lgbm.best_score_}\")\n",
    "\n",
    "pickle.dump(gs_lgbm.best_estimator_, open(\"./models/LightGBM.pkl\", \"wb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lgbm_best_params={\n",
    "    \"boosting_type\": 'gbdt',\n",
    "    \"num_leaves\" :30,\n",
    "    \"max_depth\" : -1,\n",
    "    \"learning_rate\" :0.05,\n",
    "    \"n_estimators\":5000,\n",
    "    \"objective\" : \"multiclass\",      \n",
    "    \"feature_fraction\" :0.5,\n",
    "    \"min_child_weight\" :0.1,\n",
    "    \"max_bin\": 8192,\n",
    "    \"verbosity\" :1,\n",
    "    \"num_threads\":6,\n",
    "    \"seed\":42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CiFFsWRC11U"
   },
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = load_dataset()\n",
    "X=df.drop(columns=['building_id', 'damage_grade'])\n",
    "y=df['damage_grade']\n",
    "\n",
    "#Required preprocessing: identify categorical features\n",
    "make_cat_cols=['geo_level_1_id','geo_level_2_id','geo_level_3_id','land_surface_condition', 'foundation_type', 'roof_type',\n",
    "       'ground_floor_type', 'other_floor_type', 'position',\n",
    "       'plan_configuration', 'legal_ownership_status','count_floors_pre_eq', 'has_superstructure_adobe_mud',\n",
    "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
    "       'has_superstructure_cement_mortar_stone',\n",
    "       'has_superstructure_mud_mortar_brick',\n",
    "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
    "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
    "       'legal_ownership_status', 'has_secondary_use',\n",
    "       'has_secondary_use_agriculture', 'has_secondary_use_hotel',\n",
    "       'has_secondary_use_rental', 'has_secondary_use_institution',\n",
    "       'has_secondary_use_school', 'has_secondary_use_industry',\n",
    "       'has_secondary_use_health_post', 'has_secondary_use_gov_office',\n",
    "       'has_secondary_use_use_police', 'has_secondary_use_other', 'number_of_different_superstructures', 'number_of_secondary_uses']\n",
    "\n",
    "pp = Preprocessor(compress_cols=True, make_cat_cols=make_cat_cols)\n",
    "pp.fit(X,y)\n",
    "X=pp.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SkunbmSnC11U"
   },
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    'iterations' : [1000, 2000, 5000, 7000],\n",
    "    'learning_rate' : [0.02, 0.05, 0.07],\n",
    "    'depth' : [9, 10, 12],\n",
    "    'loss_function' : ['MultiClass'],\n",
    "    'verbose' : [False],\n",
    "    'eval_metric' : ['TotalF1'],\n",
    "    'l2_leaf_reg' : [1, 2, 5, 9],\n",
    "    'border_count' : [None, 11, 15],\n",
    "    'task_type' : ['GPU']\n",
    "}\n",
    "\n",
    "gs_cat = GridSearchCV(estimator=CatBoostClassifier(),\n",
    "                    param_grid=catboost_params, \n",
    "                    verbose=2,\n",
    "                    scoring='f1_micro')\n",
    "\n",
    "gs_cat.fit(X, y, verbose=10, cat_features=make_cat_cols)\n",
    "\n",
    "print(f\"BEST MODEL: {gs_cat.best_estimator_.get_params()}\")\n",
    "print(f\"WITH MEAN SCORE: {gs_cat.best_score_}\")\n",
    "\n",
    "pickle.dump(gs_cat.best_estimator_, open(\"./models/CatBoostClassifier.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: {iterations: 5000, learning_rate: 0.05, depth: 9, loss_function: Multiclass, verbose:false, eval_metric:TotalF1, l2_leaf_reg : 2, border_count:None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WiVPVl3iC11V"
   },
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-ar5McxC11c",
    "outputId": "693533a2-07e3-42f7-a9e6-989372f3a451"
   },
   "outputs": [],
   "source": [
    "df_logit = load_dataset()\n",
    "X = df_logit.drop(columns=[\"building_id\", \"damage_grade\"])\n",
    "y = df_logit[\"damage_grade\"]\n",
    "\n",
    "one_hot_cols = [\"legal_ownership_status\",\"land_surface_condition\",\n",
    "                    \"foundation_type\",\"roof_type\",\"ground_floor_type\",\"other_floor_type\",\"position\",\"plan_configuration\"]\n",
    "target_cols = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']\n",
    "scaled_cols = ['age', 'area_percentage','count_floors_pre_eq' ,'height_percentage']\n",
    "\n",
    "pp = Preprocessor(compress_cols=True, one_hot_cols=one_hot_cols, target_cols=target_cols, scaled_cols=scaled_cols)\n",
    "pp.fit(X, y)\n",
    "X = pp.transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y)\n",
    "\n",
    "log_model = pickle.load(open(\"./models/LogisticRegression.pkl\"))\n",
    "log_model.fit(X_train, y_train)\n",
    "y_pred = log_model.predict(X_val)\n",
    "\n",
    "print(f\"GOT F1-SCORE OF: {f1_score(y_pred, y_val, average = 'micro')}\")\n",
    "\n",
    "get_confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_svm = load_dataset()\n",
    "X = df_svm.drop(columns=[\"building_id\", \"damage_grade\"])\n",
    "y = df_svm[\"damage_grade\"]\n",
    "\n",
    "one_hot_cols = [\"legal_ownership_status\",\"land_surface_condition\",\n",
    "                    \"foundation_type\",\"roof_type\",\"ground_floor_type\",\"other_floor_type\",\"position\",\"plan_configuration\"]\n",
    "target_cols = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']\n",
    "scaled_cols = ['age', 'area_percentage','count_floors_pre_eq' ,'height_percentage']\n",
    "\n",
    "pp = Preprocessor(compress_cols=True, one_hot_cols=one_hot_cols, target_cols=target_cols, scaled_cols=scaled_cols)\n",
    "pp.fit(X, y)\n",
    "X = pp.transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y)\n",
    "\n",
    "svm_model = pickle.load(open(\"./models/SVM.pkl\"))\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_val)\n",
    "\n",
    "print(f\"GOT F1-SCORE OF: {f1_score(y_pred, y_val, average = 'micro')}\")\n",
    "\n",
    "get_confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = load_dataset()\n",
    "X = df_rf.drop(columns=[\"building_id\", \"damage_grade\"])\n",
    "y = df_rf[\"damage_grade\"]\n",
    "\n",
    "one_hot_cols = [\"legal_ownership_status\",\"land_surface_condition\",\n",
    "                    \"foundation_type\",\"roof_type\",\"ground_floor_type\",\"other_floor_type\",\"position\",\"plan_configuration\"]\n",
    "target_cols = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']\n",
    "\n",
    "pp = Preprocessor(compress_cols=True, one_hot_cols=one_hot_cols, target_cols=target_cols)\n",
    "pp.fit(X, y)\n",
    "X = pp.transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y)\n",
    "\n",
    "rf_model = pickle.load(open(\"./models/RandomForestClassifier.pkl\"))\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_val)\n",
    "\n",
    "print(f\"GOT F1-SCORE OF: {f1_score(y_pred, y_val, average = 'micro')}\")\n",
    "\n",
    "get_confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = load_dataset()\n",
    "X = df_cat.drop(columns=['building_id', 'damage_grade'])\n",
    "y = df_cat['damage_grade']\n",
    "\n",
    "make_cat_cols=['geo_level_1_id','geo_level_2_id','geo_level_3_id','land_surface_condition', 'foundation_type', 'roof_type',\n",
    "       'ground_floor_type', 'other_floor_type', 'position',\n",
    "       'plan_configuration', 'legal_ownership_status','count_floors_pre_eq', 'has_superstructure_adobe_mud',\n",
    "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
    "       'has_superstructure_cement_mortar_stone',\n",
    "       'has_superstructure_mud_mortar_brick',\n",
    "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
    "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
    "       'legal_ownership_status', 'has_secondary_use',\n",
    "       'has_secondary_use_agriculture', 'has_secondary_use_hotel',\n",
    "       'has_secondary_use_rental', 'has_secondary_use_institution',\n",
    "       'has_secondary_use_school', 'has_secondary_use_industry',\n",
    "       'has_secondary_use_health_post', 'has_secondary_use_gov_office',\n",
    "       'has_secondary_use_use_police', 'has_secondary_use_other', 'number_of_different_superstructures', 'number_of_secondary_uses']\n",
    "\n",
    "pp = Preprocessor(compress_cols=True, make_cat_cols=make_cat_cols)\n",
    "pp.fit(X,y)\n",
    "X = pp.transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y)\n",
    "\n",
    "cat_model = pickle.load(open(\"./models/CatBoostClassifier.pkl\"))\n",
    "cat_model.fit(X_train, y_train, cat_features=make_cat_cols)\n",
    "y_pred = cat_model.predict(X_val)\n",
    "\n",
    "print(f\"GOT F1-SCORE OF: {f1_score(y_pred, y_val, average = 'micro')}\")\n",
    "\n",
    "get_confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=load_dataset()\n",
    "X=df.drop(columns=['building_id', 'damage_grade'])\n",
    "y=df['damage_grade']\n",
    "\n",
    "make_cat_cols = [\"legal_ownership_status\",\"land_surface_condition\",\n",
    "                    \"foundation_type\",\"roof_type\",\"ground_floor_type\",\"other_floor_type\",\"position\",\"plan_configuration\"]\n",
    "target_cols = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']\n",
    "\n",
    "pp = Preprocessor(compress_cols=True, make_cat_cols=make_cat_cols, target_cols=target_cols)\n",
    "pp.fit(X,y)\n",
    "X=pp.transform(X)\n",
    "\n",
    "cat_index = [X.columns.get_loc(name) for name in make_cat_cols]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y)          \n",
    "\n",
    "lgbm_model = pickle.load(open(\"./models/LightGBM.pkl\"))\n",
    "lgbm_model.fit(X_train, y_train, categorical_feature=cat_index)\n",
    "\n",
    "y_pred = lgbm_model.predict(X_val)\n",
    "\n",
    "print(f\"GOT F1-SCORE OF: {f1_score(y_pred, y_val, average = 'micro')}\")\n",
    "\n",
    "get_confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vjm4wWEsC11i"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYuRRyjXC11j"
   },
   "source": [
    "The preprocessing is different from each model, for this reason, we're gonna make different sections for each different model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umber\\anaconda3\\lib\\site-packages\\category_encoders\\target_encoder.py:122: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "C:\\Users\\umber\\anaconda3\\lib\\site-packages\\category_encoders\\target_encoder.py:127: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    }
   ],
   "source": [
    "# GET TRAINING SET \n",
    "df = load_dataset()\n",
    "X_train = df.drop(columns=[\"building_id\", \"damage_grade\"])\n",
    "y = df[\"damage_grade\"]\n",
    "\n",
    "# FIT THE PREPROCESSOR\n",
    "one_hot_cols = [\"legal_ownership_status\",\"land_surface_condition\",\n",
    "                    \"foundation_type\",\"roof_type\",\"ground_floor_type\",\"other_floor_type\",\"position\",\"plan_configuration\"]\n",
    "scaled_cols = ['age', 'area_percentage','count_floors_pre_eq' ,'height_percentage']\n",
    "target_cols = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']\n",
    "\n",
    "pp = Preprocessor(compress_cols=True, one_hot_cols=one_hot_cols, scaled_cols=scaled_cols, target_cols=target_cols)\n",
    "pp.fit(X_train, y)\n",
    "\n",
    "# GET TEST SET AND TRANSFORM IT\n",
    "df_test = load_dataset(train = False)\n",
    "X_test = df_test.drop(columns=['building_id'])\n",
    "X_test = pp.transform(X_test)\n",
    "\n",
    "# LOAD THE MODEL AND PREDICT\n",
    "lr_model = pickle.load(open(\"./models/LogisticRegression.pkl\", \"rb\"))\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test)\n",
    "\n",
    "# SUBMISSION\n",
    "X_sub_lr = pd.DataFrame(df_test['building_ids'])\n",
    "X_sub_lr['damage_grade'] = y_pred_lr\n",
    "X_sub_lr.to_csv(f\"./prediction/LogisticRegression_sub.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Okj3WzLtC11l"
   },
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MfJgw-XkC11l"
   },
   "outputs": [],
   "source": [
    "# GET TRAINING SET \n",
    "df = load_dataset()\n",
    "X_train = df.drop(columns=[\"building_id\", \"damage_grade\"])\n",
    "y = df[\"damage_grade\"]\n",
    "\n",
    "# FIT THE PREPROCESSOR\n",
    "one_hot_cols = [\"legal_ownership_status\",\"land_surface_condition\",\n",
    "                    \"foundation_type\",\"roof_type\",\"ground_floor_type\",\"other_floor_type\",\"position\",\"plan_configuration\"]\n",
    "scaled_cols = ['age', 'area_percentage','count_floors_pre_eq' ,'height_percentage']\n",
    "target_cols = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']\n",
    "\n",
    "pp = Preprocessor(compress_cols=True, one_hot_cols=one_hot_cols, scaled_cols=scaled_cols, target_cols=target_cols)\n",
    "pp.fit(X_train, y)\n",
    "\n",
    "# GET TEST SET AND TRANSFORM IT\n",
    "df_test = load_dataset(train = False)\n",
    "X_test = df_test.drop(columns=['building_id'])\n",
    "X_test = pp.transform(X_test)\n",
    "\n",
    "# LOAD THE MODEL AND PREDICT\n",
    "svm_model = pickle.load(open(\"./models/SVM.pkl\", \"rb\"))\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "y_pred_proba_svm = svm_model.predict_proba(X_test)\n",
    "\n",
    "# SUBMISSION\n",
    "X_sub_svm = pd.DataFrame(df_test['building_ids'])\n",
    "X_sub_svm['damage_grade'] = y_pred_svm\n",
    "X_sub_svm.to_csv(f\"./prediction/SVM_sub.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_svLAwqC11j"
   },
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFiE7w9yC11j"
   },
   "outputs": [],
   "source": [
    "# GET TRAINING SET \n",
    "df_rf = load_dataset()\n",
    "X_train = df_rf.drop(columns=[\"building_id\", \"damage_grade\"])\n",
    "y = df_rf[\"damage_grade\"]\n",
    "\n",
    "# FIT THE PREPROCESSOR\n",
    "one_hot_cols = [\"legal_ownership_status\",\"land_surface_condition\",\n",
    "                    \"foundation_type\",\"roof_type\",\"ground_floor_type\",\"other_floor_type\",\"position\",\"plan_configuration\"]\n",
    "target_cols = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']\n",
    "\n",
    "pp = Preprocessor(compress_cols=True, one_hot_cols=one_hot_cols, target_cols=target_cols)\n",
    "pp.fit(X_train, y)\n",
    "\n",
    "# GET TEST SET AND TRANSFORM IT\n",
    "df_test = load_dataset(train = False)\n",
    "X_test = df_test.drop(columns=['building_id'])\n",
    "X_test = pp.transform(X_test)\n",
    "\n",
    "# LOAD THE MODEL AND PREDICT\n",
    "rf_model = pickle.load(open(\"./models/RandomForestClassifier.pkl\", \"rb\"))\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "# SUBMISSION\n",
    "X_sub_rf = pd.DataFrame(df_test['building_ids'])\n",
    "X_sub_rf['damage_grade'] = y_pred_rf\n",
    "X_sub_rf.to_csv(f\"./prediction/RandomForestClassifier_sub.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VWdbnQtC79t"
   },
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pji_5IgxIDbp"
   },
   "outputs": [],
   "source": [
    "# GET TRAINING SET \n",
    "df = load_dataset()\n",
    "X_train = df.drop(columns=[\"building_id\", \"damage_grade\"])\n",
    "y = df[\"damage_grade\"]\n",
    "\n",
    "# FIT THE PREPROCESSOR\n",
    "make_cat_cols = [\"legal_ownership_status\",\"land_surface_condition\",\n",
    "                    \"foundation_type\",\"roof_type\",\"ground_floor_type\",\"other_floor_type\",\"position\",\"plan_configuration\"]\n",
    "\n",
    "target_cols = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']\n",
    "\n",
    "pp = Preprocessor(compress_cols=True, target_cols=target_cols, make_cat_cols=make_cat_cols)\n",
    "pp.fit(X_train, y)\n",
    "\n",
    "# GET TEST SET AND TRANSFORM IT\n",
    "df_test = load_dataset(train = False)\n",
    "X_test = df_test.drop(columns=['building_id'])\n",
    "X_test = pp.transform(X_test)\n",
    "\n",
    "# LOAD THE MODEL AND PREDICT\n",
    "lgbm_model = pickle.load(open(\"./models/LightGBM.pkl\", \"rb\"))\n",
    "y_pred_lgbm = lgbm_model.predict(X_test)\n",
    "y_pred_proba_lgbm = lgbm_model.predict_proba(X_test)\n",
    "\n",
    "# SUBMISSION\n",
    "X_sub_lgbm = pd.DataFrame(df_test['building_ids'])\n",
    "X_sub_lgbm['damage_grade'] = y_pred_lgbm\n",
    "X_sub_lgbm.to_csv(f\"./prediction/LightGBM_sub.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h83f9OmGt7YO"
   },
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GXcWgeNTt-lv"
   },
   "outputs": [],
   "source": [
    "# GET TRAINING SET \n",
    "df = load_dataset()\n",
    "X_train = df.drop(columns=[\"building_id\", \"damage_grade\"])\n",
    "y = df[\"damage_grade\"]\n",
    "\n",
    "# FIT THE PREPROCESSOR\n",
    "make_cat_cols = ['geo_level_1_id','geo_level_2_id','geo_level_3_id','land_surface_condition', 'foundation_type', 'roof_type',\n",
    "       'ground_floor_type', 'other_floor_type', 'position',\n",
    "       'plan_configuration', 'legal_ownership_status','count_floors_pre_eq', 'has_superstructure_adobe_mud',\n",
    "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
    "       'has_superstructure_cement_mortar_stone',\n",
    "       'has_superstructure_mud_mortar_brick',\n",
    "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
    "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
    "       'legal_ownership_status', 'has_secondary_use',\n",
    "       'has_secondary_use_agriculture', 'has_secondary_use_hotel',\n",
    "       'has_secondary_use_rental', 'has_secondary_use_institution',\n",
    "       'has_secondary_use_school', 'has_secondary_use_industry',\n",
    "       'has_secondary_use_health_post', 'has_secondary_use_gov_office',\n",
    "       'has_secondary_use_use_police', 'has_secondary_use_other', 'number_of_different_superstructures', 'number_of_secondary_uses']\n",
    "\n",
    "pp = Preprocessor(compress_cols=True, make_cat_cols=make_cat_cols)\n",
    "pp.fit(X_train, y)\n",
    "\n",
    "# GET TEST SET AND TRANSFORM IT\n",
    "df_test = load_dataset(train = False)\n",
    "X_test = df_test.drop(columns=['building_id'])\n",
    "X_test = pp.transform(X_test)\n",
    "\n",
    "# LOAD THE MODEL AND PREDICT\n",
    "cat_model = pickle.load(open(\"./models/CatBoost.pkl\", \"rb\"))\n",
    "y_pred_cat = cat_model.predict(X_test)\n",
    "y_pred_proba_cat = cat_model.predict_proba(X_test)\n",
    "\n",
    "# SUBMISSION\n",
    "X_sub_cat = pd.DataFrame(df_test['building_ids'])\n",
    "X_sub_cat['damage_grade'] = y_pred_cat\n",
    "X_sub_cat.to_csv(f\"./prediction/CatBoost_sub.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_ensembles = []\n",
    "\n",
    "y_pred_proba_ensembles.append(y_pred_proba_rf)\n",
    "y_pred_proba_ensembles.append(y_pred_proba_lgbm)\n",
    "y_pred_proba_ensembles.append(y_pred_proba_cat)\n",
    "\n",
    "y_pred_proba_ensembles = np.array(y_pred_proba_ensembles)\n",
    "\n",
    "y_pred_ensembles = majority_vote(y_pred_proba_ensembles, [0.8, 1., 1.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=load_dataset(train=False)\n",
    "X_sub_ens = pd.DataFrame(df_test['building_id'])\n",
    "X_sub_ens['damage_grade'] = y_pred_ensembles\n",
    "\n",
    "X_sub_ens.to_csv(f\"./prediction/Ensembles_sub.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d9fb62c3fb36c550249c060199eec3b3c9c8cc2026ad75ac4a4abaca116f9c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
